# ğŸš€ Career Advisor AI

**Career Advisor AI** is an AI-powered Personalized Career & Skills Advisor that recommends career paths, performs skill gap analysis, and generates learning paths.  
Built with **FastAPI (backend)** and **Streamlit (frontend)** and optionally powered by the Gemini / Google Generative AI.

---

## ğŸ“‚ Project Structure

career-advisor-ai/
â”œâ”€â”€ backend/ # FastAPI backend (APIs)
â”‚ â”œâ”€â”€ main.py
â”‚ â””â”€â”€ test.py
â”œâ”€â”€ frontend/ # Streamlit frontend (UI)
â”‚ â””â”€â”€ app.py
â”œâ”€â”€ data/ # Sample datasets for testing
â”‚ â”œâ”€â”€ careers.csv
â”‚ â””â”€â”€ careers.json
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md


---

## âš¡ Features

- AI-based career recommendations (via Gemini / LLM)
- Skill gap analysis & recommended learning path
- FastAPI backend with JSON endpoints
- Streamlit frontend for interactive demo
- Easy local setup and cloud deployment

---

## ğŸ”§ Quick Setup

> Make sure you are in the project root `career-advisor-ai/`

### 1. Create and activate virtual environment
**Windows (PowerShell)**
```powershell
python -m venv venv
.\venv\Scripts\Activate.ps1

macOS / Linux
python3 -m venv venv
source venv/bin/activate

Install dependencies
pip install -r requirements.txt

If you run into dependency conflicts, create a fresh virtual environment and install minimal required packages:
pip install fastapi uvicorn streamlit google-generativeai requests pandas python-dotenv

â–¶ï¸ Run Locally
1) Start the backend (FastAPI)
cd backend
uvicorn main:app --reload


Backend default: http://127.0.0.1:8000
Swagger UI: http://127.0.0.1:8000/docs

Example health check:
GET http://127.0.0.1:8000/

2) Start the frontend (Streamlit)

Open a new terminal (keep backend running):

cd frontend
streamlit run app.py

Streamlit UI: http://localhost:8501
ğŸŒ Example API Usage
POST /ask (example)

Request
curl -X POST "http://127.0.0.1:8000/ask" \
  -H "Content-Type: application/json" \
  -d '{"query": "Suggest top AI careers for a student who knows Python and ML"}'


Expected Response (JSON)

{
  "response": "1. Data Scientist â€” ...\n2. ML Engineer â€” ...\n3. Prompt Engineer â€” ..."
}

ğŸ“ Sample data (in data/)

data/careers.csv (example rows)

Career,Skills,Average_Salary,Domain
Data Scientist,Python; Machine Learning; Statistics,120000,Data Science
Software Engineer,Java; C++; Problem Solving,100000,Software Development
AI Researcher,Deep Learning; NLP; Research,130000,Artificial Intelligence
UI/UX Designer,Wireframing; Figma; Creativity,80000,Design
Cybersecurity Analyst,Networking; Security; Risk Analysis,95000,Cybersecurity

data/careers.json (example)

[
  {
    "career": "Data Scientist",
    "skills": ["Python", "Machine Learning", "Statistics"],
    "average_salary": 120000,
    "domain": "Data Science"
  }
]


Your backend can load these files and match user skills to roles.

ğŸ§­ How it works (high level)
Frontend (Streamlit) sends user input (skills / question) to backend /ask.
Backend (FastAPI) either:
Performs local matching using data/careers.csv (skill overlap / embeddings), or
Calls Gemini/LLM (google-generativeai) to generate personalized learning path + interview tips.
Backend returns structured plain text or JSON; frontend renders it.

ğŸ” Environment & API Keys
Keep your LLM/API keys out of source control.
Use a .env file + python-dotenv or platform secrets manager.
Example .env (do not commit):
GEMINI_API_KEY=your_api_key_here


Load in Python (example):
from dotenv import load_dotenv
import os
load_dotenv()
api_key = os.getenv("GEMINI_API_KEY")

ğŸš€ Deployment (quick notes)
Frontend: Streamlit Cloud (share.streamlit.io) â€” easiest for quick demos.
Backend: Render, Railway, or Heroku â€” host FastAPI and provide a public URL.
After deploying backend, update frontend/app.py backend URL to the public one.
Render start command example:
uvicorn main:app --host 0.0.0.0 --port 10000

ğŸ§ª Troubleshooting Tips
Error: File does not exist: app.py â†’ ensure you run streamlit run app.py from the frontend/ folder where app.py exists.
PermissionDenied or 403 with Gemini â†’ enable Generative Language API for the correct Google Cloud project and ensure billing/credentials are correct.
Dependency conflicts â†’ use a fresh venv and install minimal required packages; pin versions in requirements.txt after confirming.

âœ… Useful Commands (summary)
# from project root
# create venv (Windows)
python -m venv venv
.\venv\Scripts\Activate.ps1

# install
pip install -r requirements.txt

# run backend
cd backend
uvicorn main:app --reload

# run frontend (in new terminal)
cd frontend
streamlit run app.py

ğŸ§¾ Author
Vandana D L (Vandanaputti)
Email: vandanadlputti@gmail.com

If you want, I can:
Add example screenshots to the README,
Add ready-made badge links (build/deploy),
Or generate a Contributing and License section.
